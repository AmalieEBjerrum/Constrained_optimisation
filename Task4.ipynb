{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd3d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def line_search_sqp(f, grad_f, h, jac_h, g, jac_g, hess_lagrangian=None, x0=None, tol=1e-6, max_iter=100, c1=1e-4, tau=0.5, use_bfgs=True):\n",
    "    \"\"\"\n",
    "    Sequential Quadratic Programming (SQP) with line search.\n",
    "    Parameters:\n",
    "    f: Objective function\n",
    "    grad_f: Gradient of the objective function\n",
    "    h: Equality constraint function\n",
    "    jac_h: Jacobian of the equality constraint function\n",
    "    g: Inequality constraint function\n",
    "    jac_g: Jacobian of the inequality constraint function\n",
    "    hess_lagrangian: Hessian of the Lagrangian function (optional)\n",
    "    x0: Initial guess\n",
    "    tol: Tolerance for convergence\n",
    "    max_iter: Maximum number of iterations\n",
    "    c1: Wolfe condition parameter which is used to determine the step length\n",
    "    tau: Step length reduction factor\n",
    "    use_bfgs: Whether to use BFGS for Hessian approximation when True then the BFGS algorithm is used, when not then the user provided hessian is used\n",
    "    Returns: x: Optimal solution\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(x0)\n",
    "    x_k = np.array(x0)\n",
    "    lambda_k = np.zeros_like(h(x_k))\n",
    "    mu_k = np.zeros_like(g(x_k))\n",
    "    B_k = np.eye(n) if use_bfgs else hess_lagrangian(x_k, lambda_k, mu_k)\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        grad_L = grad_f(x_k) - jac_h(x_k).T @ lambda_k - jac_g(x_k).T @ mu_k\n",
    "\n",
    "        try:\n",
    "            p_k = -np.linalg.solve(B_k, grad_L)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Hessian not invertible\", k)\n",
    "            break\n",
    "\n",
    "        def merit(alpha):\n",
    "            x_alpha = x_k + alpha * p_k\n",
    "            return (\n",
    "                f(x_alpha)\n",
    "                + np.sum(np.abs(h(x_alpha)))\n",
    "                + np.sum(np.abs(np.minimum(0, g(x_alpha))))\n",
    "            )\n",
    "\n",
    "        phi_0 = merit(0)\n",
    "        phi_prime_0 = grad_f(x_k).T @ p_k \\\n",
    "                      - lambda_k.T @ np.abs(h(x_k)) \\\n",
    "                      - mu_k.T @ np.abs(np.minimum(0, g(x_k)))\n",
    "\n",
    "        alpha = 1.0\n",
    "        while merit(alpha) > phi_0 + c1 * alpha * phi_prime_0:\n",
    "            alpha *= tau\n",
    "\n",
    "        x_new = x_k + alpha * p_k\n",
    "        lambda_new = lambda_k  # simplified\n",
    "        mu_new = mu_k          # simplified\n",
    "\n",
    "        if use_bfgs:\n",
    "            s_k = x_new - x_k\n",
    "            y_k = (grad_f(x_new) - jac_h(x_new).T @ lambda_new - jac_g(x_new).T @ mu_new) - grad_L\n",
    "\n",
    "            if s_k.T @ y_k >= 0.2 * s_k.T @ B_k @ s_k:\n",
    "                theta = 1.0\n",
    "            else:\n",
    "                theta = 0.8 * (s_k.T @ B_k @ s_k) / (s_k.T @ B_k @ s_k - s_k.T @ y_k)\n",
    "\n",
    "            r_k = theta * y_k + (1 - theta) * (B_k @ s_k)\n",
    "            B_k += np.outer(r_k, r_k) / (s_k.T @ r_k) - \\\n",
    "                   (B_k @ np.outer(s_k, s_k) @ B_k) / (s_k.T @ B_k @ s_k)\n",
    "\n",
    "        if np.linalg.norm(p_k) < tol:\n",
    "            break\n",
    "\n",
    "        x_k = x_new\n",
    "        lambda_k = lambda_new\n",
    "        mu_k = mu_new\n",
    "\n",
    "    x_opt = x_k\n",
    "    f_val = f(x_opt)\n",
    "    h_val = h(x_opt)\n",
    "    g_val = g(x_opt)\n",
    "\n",
    "    print(\"Optimal solution x* =\", x_opt)\n",
    "    print(\"Objective value f(x*) =\", f_val)\n",
    "    print(\"Equality constraint h(x*) =\", h_val)\n",
    "    print(\"Inequality constraint g(x*) =\", g_val)\n",
    "\n",
    "    return x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b275dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution x* = [2.99999984 2.00000059]\n",
      "Objective value f(x*) = 4.915222144808569e-12\n",
      "Equality constraint h(x*) = []\n",
      "Inequality constraint g(x*) = [22.99999782  8.0000065 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.99999984, 2.00000059])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Himmelblau test function\n",
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2\n",
    "\n",
    "def grad_f(x):\n",
    "    x1, x2 = x\n",
    "    df_dx1 = 4 * x1 * (x1**2 + x2 - 11) + 2 * (x1 + x2**2 - 7)\n",
    "    df_dx2 = 2 * (x1**2 + x2 - 11) + 4 * x2 * (x1 + x2**2 - 7)\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "# Constraints\n",
    "def h(x): \n",
    "    return np.array([])\n",
    "\n",
    "def jac_h(x):  # jac\n",
    "    return np.empty((0, len(x)))\n",
    "\n",
    "def g(x): \n",
    "    x1, x2 = x\n",
    "    return np.array([\n",
    "        (x1 + 2)**2 - x2,\n",
    "        -4 * x1 + 10 * x2\n",
    "    ])\n",
    "\n",
    "def jac_g(x):\n",
    "    x1, x2 = x\n",
    "    return np.array([\n",
    "        [2 * (x1 + 2), -1],\n",
    "        [-4, 10]\n",
    "    ])\n",
    "\n",
    "# Call SQP algorithm\n",
    "x0 = np.array([0.0, 0.0])\n",
    "optimal_x = line_search_sqp(f, grad_f, h, jac_h, g, jac_g, x0=x0, tol=1e-6, max_iter=100, c1=1e-4, tau=0.5, use_bfgs=True)\n",
    "optimal_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f581ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trust_region_sqp(\n",
    "    f, grad_f, h, jac_h, g, jac_g,\n",
    "    hess_lagrangian=None,\n",
    "    x0=None,\n",
    "    tol=1e-6, max_iter=100,\n",
    "    delta0=1.0, delta_max=10.0,\n",
    "    eta1=0.1, eta2=0.75,\n",
    "    gamma_inc=2.0, gamma_dec=0.5,\n",
    "    use_bfgs=True\n",
    "):\n",
    "    n = len(x0)\n",
    "    x_k = np.array(x0)\n",
    "    lambda_k = np.zeros_like(h(x_k))\n",
    "    mu_k = np.zeros_like(g(x_k))\n",
    "    B_k = np.eye(n) if use_bfgs else hess_lagrangian(x_k, lambda_k, mu_k)\n",
    "    delta_k = delta0\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        grad_L = grad_f(x_k) - jac_h(x_k).T @ lambda_k - jac_g(x_k).T @ mu_k\n",
    "\n",
    "        try:\n",
    "            p_full = -np.linalg.solve(B_k, grad_L)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Hessian not invertible\")\n",
    "            break\n",
    "\n",
    "        if np.linalg.norm(p_full) > delta_k:\n",
    "            p_k = -delta_k * grad_L / np.linalg.norm(grad_L)\n",
    "        else:\n",
    "            p_k = p_full\n",
    "\n",
    "        model_pred = f(x_k)\n",
    "        model_val = f(x_k) + grad_f(x_k).T @ p_k + 0.5 * p_k.T @ B_k @ p_k\n",
    "        f_new = f(x_k + p_k)\n",
    "\n",
    "        rho_k = (f(x_k) - f_new) / (model_pred - model_val + 1e-10)  # avoid div by zero\n",
    "\n",
    "        if rho_k > eta1:\n",
    "            x_new = x_k + p_k\n",
    "        else:\n",
    "            x_new = x_k  # reject step\n",
    "\n",
    "        if rho_k > eta2:\n",
    "            delta_k = min(gamma_inc * delta_k, delta_max)\n",
    "        elif rho_k < eta1:\n",
    "            delta_k *= gamma_dec\n",
    "\n",
    "        lambda_new = lambda_k\n",
    "        mu_new = mu_k\n",
    "\n",
    "        if use_bfgs and not np.array_equal(x_new, x_k):\n",
    "            s_k = x_new - x_k\n",
    "            y_k = grad_f(x_new) - jac_h(x_new).T @ lambda_new - jac_g(x_new).T @ mu_new - grad_L\n",
    "\n",
    "            if s_k.T @ y_k >= 0.2 * s_k.T @ B_k @ s_k:\n",
    "                theta = 1.0\n",
    "            else:\n",
    "                theta = 0.8 * (s_k.T @ B_k @ s_k) / (s_k.T @ B_k @ s_k - s_k.T @ y_k)\n",
    "\n",
    "            r_k = theta * y_k + (1 - theta) * B_k @ s_k\n",
    "            B_k += np.outer(r_k, r_k) / (s_k.T @ r_k + 1e-10) \\\n",
    "                 - (B_k @ np.outer(s_k, s_k) @ B_k) / (s_k.T @ B_k @ s_k + 1e-10)\n",
    "\n",
    "        if np.linalg.norm(p_k) < tol:\n",
    "            break\n",
    "\n",
    "        x_k = x_new\n",
    "        lambda_k = lambda_new\n",
    "        mu_k = mu_new\n",
    "\n",
    "    x_opt = x_k\n",
    "    f_val = f(x_opt)\n",
    "    h_val = h(x_opt)\n",
    "    g_val = g(x_opt)\n",
    "\n",
    "    print(\"Optimal solution x* =\", x_opt)\n",
    "    print(\"Objective value f(x*) =\", f_val)\n",
    "    print(\"Equality constraint h(x*) =\", h_val)\n",
    "    print(\"Inequality constraint g(x*) =\", g_val)\n",
    "\n",
    "    return x_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28cdba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution x* = [3. 2.]\n",
      "Objective value f(x*) = 2.6448844383683955e-18\n",
      "Equality constraint h(x*) = []\n",
      "Inequality constraint g(x*) = [23.  8.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3., 2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Trust Region SQP on Himmelblau's test problem\n",
    "\n",
    "trust_region_sqp(\n",
    "    f=f,\n",
    "    grad_f=grad_f,\n",
    "    h=h,\n",
    "    jac_h=jac_h,\n",
    "    g=g,\n",
    "    jac_g=jac_g,\n",
    "    x0=np.array([0.0, 0.0]),\n",
    "    tol=1e-6,\n",
    "    max_iter=100,\n",
    "    delta0=1.0,\n",
    "    delta_max=5.0,\n",
    "    eta1=0.1,\n",
    "    eta2=0.75,\n",
    "    gamma_inc=2.0,\n",
    "    gamma_dec=0.5,\n",
    "    use_bfgs=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f6930c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3**2+2-11)**2 + (3+2**2-7)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3912a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
